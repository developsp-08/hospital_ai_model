{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87735fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. PROJECT SETUP ---\n",
      "Data file expected at: data/Training_Data_Final.xlsx\n",
      "Model will be saved to: models/inventory_model.pkl\n",
      "\n",
      "--- 2A. RAW DATA CLEANED ---\n",
      "Total cleaned rows (Pre-Aggregation): 1331\n",
      "\n",
      "--- 2B. FINAL TRAINING DATA SAMPLE (INDIVIDUAL SKU) ---\n",
      "\n",
      "[--- SAMPLE DATA HEAD ---]\n",
      "         Date             SKU  Usage_Qty  Patient_Count  Total_SKU_Usage  lag1\n",
      "40 2023-02-01           10300          1           1193               47   1.0\n",
      "41 2023-02-01           10304          1           1193               47   1.0\n",
      "44 2023-02-01  42131611000009          1           1193               47   1.0\n",
      "46 2023-02-01  42132205000055          1           1193               47   1.0\n",
      "47 2023-02-01  42132205000057          1           1193               47   1.0\n",
      "\n",
      "[--- FINAL DATA SHAPE ---]\n",
      "Final training shape: (1103, 12)\n",
      "Base Date for modeling: 2023-01-01\n",
      "Max Date for training: 2025-09-01\n",
      "\n",
      "✅ Loaded and transformed data successfully from data/Training_Data_Final.xlsx\n",
      "Model Trained. R-squared (simple): 0.0304\n",
      "Model and Metadata saved successfully to models/inventory_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# train_and_save_model.ipynb (FINAL PRODUCTION VERSION)\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# BUMP DISPLAY LIMITS\n",
    "pd.set_option('display.max_rows', 5000) \n",
    "pd.set_option('display.max_columns', 50) \n",
    "\n",
    "# --- Cell 1: Import Libraries and Setup ---\n",
    "\n",
    "DATA_FILE_PATH = 'data/Training_Data_Final.xlsx' \n",
    "MODEL_PATH = 'models/inventory_model.pkl'\n",
    "# Features ที่ใช้ทำนาย (Usage_Qty ราย SKU เป็น Target)\n",
    "X_features = ['day_index', 'month_num', 'year_num', 'Patient_Count', 'lag1', 'Total_SKU_Usage'] \n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "print(\"--- 1. PROJECT SETUP ---\")\n",
    "print(f\"Data file expected at: {DATA_FILE_PATH}\")\n",
    "print(f\"Model will be saved to: {MODEL_PATH}\")\n",
    "\n",
    "# --- Cell 2: โหลดและเตรียมข้อมูล (Prediction Target: Usage_Qty ราย SKU) ---\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "base_date = pd.to_datetime('2024-01-01')\n",
    "\n",
    "try:\n",
    "    # 1. โหลดไฟล์ Training Data Final\n",
    "    df_raw = pd.read_excel(DATA_FILE_PATH) \n",
    "    \n",
    "    # 2. Cleansing และ Feature Engineering\n",
    "    df_raw.columns = df_raw.columns.astype(str)\n",
    "    df_raw['Usage_Qty'] = pd.to_numeric(df_raw['Usage_Qty'], errors='coerce') \n",
    "    \n",
    "    # กำหนดคอลัมน์ที่จำเป็นต่อการเทรน (ไม่รวม SOH)\n",
    "    subset_for_dropna = ['Date', 'Usage_Qty', 'Patient_Count', 'SKU', 'Total_SKU_Usage', 'Lead_Time_Days', 'Safety_Stock_Qty', 'Unit_Cost']\n",
    "    \n",
    "    df_raw = df_raw.dropna(subset=subset_for_dropna)\n",
    "    df_raw = df_raw[df_raw['Usage_Qty'] > 0]\n",
    "    \n",
    "    print(\"\\n--- 2A. RAW DATA CLEANED ---\")\n",
    "    print(f\"Total cleaned rows (Pre-Aggregation): {df_raw.shape[0]}\")\n",
    "    \n",
    "    # 3. *** FINAL ROBUSTNESS FIX: ENFORCE UNIQUENESS & SUM USAGE ***\n",
    "    # ถ้ามี [Date + SKU] ซ้ำกัน ให้รวมยอด Usage_Qty เข้าไป\n",
    "    agg_dict = {\n",
    "        'Usage_Qty': 'sum',\n",
    "        'Patient_Count': 'first',\n",
    "        'Total_SKU_Usage': 'first',\n",
    "        'Lead_Time_Days': 'first',\n",
    "        'Safety_Stock_Qty': 'first',\n",
    "        'Unit_Cost': 'first',\n",
    "    }\n",
    "\n",
    "    # Group By Date และ SKU เพื่อรวมยอด Usage_Qty ที่ซ้ำกัน\n",
    "    df_raw = df_raw.groupby(['Date', 'SKU'], as_index=False).agg(agg_dict)\n",
    "    \n",
    "    # 4. สร้าง Time Features\n",
    "    base_date = df_raw['Date'].min()\n",
    "    df_raw['day_index'] = (df_raw['Date'] - base_date).dt.days\n",
    "    df_raw['month_num'] = df_raw['Date'].dt.month\n",
    "    df_raw['year_num'] = df_raw['Date'].dt.year\n",
    "\n",
    "    # 5. สร้าง Lagged Features (ยอดใช้เดือนก่อน)\n",
    "    df_raw['lag1'] = df_raw.groupby('SKU')['Usage_Qty'].shift(1)\n",
    "    \n",
    "    # 6. *** FINAL PREPARATION ***\n",
    "    df_train = df_raw.dropna(subset=['lag1'])\n",
    "\n",
    "    # 7. บันทึก Metadata สุดท้าย\n",
    "    final_item_list = df_raw['SKU'].unique().tolist()\n",
    "    max_date = df_train['Date'].max()\n",
    "    \n",
    "    if df_train.empty:\n",
    "        raise ValueError(\"Data frame is empty after processing. Cannot train model.\")\n",
    "        \n",
    "    print(\"\\n--- 2B. FINAL TRAINING DATA SAMPLE (INDIVIDUAL SKU) ---\")\n",
    "    \n",
    "    # [1] แสดงตัวอย่างข้อมูล 5 แถวแรก (Sample Data Head)\n",
    "    print(\"\\n[--- SAMPLE DATA HEAD ---]\")\n",
    "    print(df_train[['Date', 'SKU', 'Usage_Qty', 'Patient_Count', 'Total_SKU_Usage', 'lag1']].head())\n",
    "\n",
    "    # [2] แสดงสรุปขนาดข้อมูล (Final Metrics)\n",
    "    print(\"\\n[--- FINAL DATA SHAPE ---]\")\n",
    "    print(f\"Final training shape: {df_train.shape}\")\n",
    "    print(f\"Base Date for modeling: {base_date.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Max Date for training: {max_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    print(f\"\\n✅ Loaded and transformed data successfully from {DATA_FILE_PATH}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n⚠️ **FATAL DATA ERROR** ({type(e).__name__}: {e}). Using Mock Data for training instead.\")\n",
    "    \n",
    "    # โค้ด Mock Data สำรอง (เพื่อให้ API ทำงานได้)\n",
    "    np.random.seed(42)\n",
    "    days = pd.date_range(start='2024-01-01', periods=100)\n",
    "    base_date = pd.to_datetime('2024-01-01')\n",
    "    max_date = days.max()\n",
    "    final_item_list = ['10300', '42132']\n",
    "    df_mock = pd.DataFrame({\n",
    "        'Date': np.repeat(days, 2),\n",
    "        'SKU': np.tile(final_item_list, 100),\n",
    "        'Usage_Qty': np.random.randint(10, 50, size=200) + np.arange(200) * 0.1,\n",
    "        'Patient_Count': np.repeat(1500 + np.random.randint(-100, 100, size=100), 2)\n",
    "    }).sort_values(by='Date')\n",
    "    df_mock['Total_SKU_Usage'] = df_mock.groupby('Date')['Usage_Qty'].transform('sum')\n",
    "    df_mock['day_index'] = (df_mock['Date'] - df_mock['Date'].min()).dt.days\n",
    "    df_mock['month_num'] = df_mock['Date'].dt.month\n",
    "    df_mock['year_num'] = df_mock['Date'].dt.year\n",
    "    df_mock['lag1'] = df_mock.groupby('SKU')['Usage_Qty'].shift(1)\n",
    "    df_train = df_mock.dropna()\n",
    "\n",
    "# --- Cell 3: เทรน Model (XGBoost Regressor) ---\n",
    "\n",
    "X_train = df_train[X_features]\n",
    "y_train = df_train['Usage_Qty'] # Target คือยอดใช้ราย SKU\n",
    "\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.05, n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "r_squared = model.score(X_train, y_train)\n",
    "print(f\"Model Trained. R-squared (simple): {r_squared:.4f}\") \n",
    "\n",
    "# --- Cell 4: บันทึก Model และ Metadata สำคัญ ---\n",
    "\n",
    "model_metadata = {\n",
    "    'model': model,\n",
    "    'base_date': base_date,\n",
    "    'max_date': max_date,\n",
    "    'item_list': final_item_list,\n",
    "    'features': X_features\n",
    "}\n",
    "dump(model_metadata, MODEL_PATH)\n",
    "\n",
    "print(f\"Model and Metadata saved successfully to {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b6d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0b8c0-eef3-4367-9729-741956a6df91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
